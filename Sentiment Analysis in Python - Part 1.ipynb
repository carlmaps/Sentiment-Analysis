{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis in Python - Part 1\n",
    "\n",
    "In today's topic we will discuss sentiment analysis using Python. We will be using the movies review datasaet which can be downloaded from http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "**Sentiment Analysis** is the process of identifying or categorizing an opinion/s expressed in words or texts in order to know wether a particular product, movie, topic, etc is either negative or positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data Files\n",
    "The dataset is for binary sentiment classification containing 25000 training data and 25000 test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"aclImdb/\"\n",
    "positiveFiles_train = [x for x in os.listdir(\"aclImdb/train/pos/\") if x.endswith(\".txt\")]\n",
    "negativeFiles_train = [x for x in os.listdir(\"aclImdb/train/neg/\") if x.endswith(\".txt\")]\n",
    "\n",
    "positiveFiles_test = [x for x in os.listdir(\"aclImdb/test/pos/\") if x.endswith(\".txt\")]\n",
    "negativeFiles_test = [x for x in os.listdir(\"aclImdb/test/neg/\") if x.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the folder of the downloaded dataset, it can seen that each train and test folders both have a pos and neg folders.\n",
    "The pos folder contains the positve movie reviews while the neg folder contains the negative movie review. As shown on the print command below, training data set is balanced. It contains 12500 positive reviews data and 12500 negative reviews data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in train(pos) data: 12500\n",
      "Number of documents in train(neg) data: 12500\n",
      "Number of documents in test(pos) data: 12500\n",
      "Number of documents in test(neg) data: 12500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in train(pos) data: {}\".format(len(positiveFiles_train)))\n",
    "print(\"Number of documents in train(neg) data: {}\".format(len(negativeFiles_train)))\n",
    "\n",
    "print(\"Number of documents in test(pos) data: {}\".format(len(positiveFiles_test)))\n",
    "print(\"Number of documents in test(neg) data: {}\".format(len(negativeFiles_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file content into a list\n",
    "\n",
    "Code below will read the content of all the text files in the pos and neg folder. The text content is then save into a list. Afterwhich, the two lists (positiveReviews and negativeReviews) will be concatinated into a single pandas dataframe named **train_reviews**. The concatinated dataframe has 3 columns: **review**, **label** and the **file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReviews, negativeReviews = [], []\n",
    "for pfile in positiveFiles_train:\n",
    "    with open(path + \"train/pos/\" + pfile, encoding=\"latin1\") as f:\n",
    "        positiveReviews.append(f.read())\n",
    "for nfile in negativeFiles_train:\n",
    "    with open(path + \"train/neg/\" +nfile, encoding=\"latin1\") as f:\n",
    "        negativeReviews.append(f.read())\n",
    "        \n",
    "\n",
    "train_reviews = pd.concat([pd.DataFrame({\"review\":positiveReviews, \"label\":1, \"file\":positiveFiles_train}),\n",
    "                           pd.DataFrame({\"review\":negativeReviews, \"label\":0, \"file\":negativeFiles_train})], \n",
    "                           ignore_index=True).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same steps is being implemented on the test data to save and convert the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReviews, negativeReviews = [], []\n",
    "for pfile in positiveFiles_test:\n",
    "    with open(path + \"test/pos/\" + pfile, encoding=\"latin1\") as f:\n",
    "        positiveReviews.append(f.read())\n",
    "for nfile in negativeFiles_test:\n",
    "    with open(path + \"test/neg/\" + nfile, encoding=\"latin1\") as f:\n",
    "        negativeReviews.append(f.read())\n",
    "        \n",
    "\n",
    "test_reviews = pd.concat([pd.DataFrame({\"review\":positiveReviews, \"label\":1, \"file\":positiveFiles_test}),\n",
    "                          pd.DataFrame({\"review\":negativeReviews, \"label\":0, \"file\":negativeFiles_test})], \n",
    "                          ignore_index=True).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12704</th>\n",
       "      <td>For months I've been hearing about this little...</td>\n",
       "      <td>0</td>\n",
       "      <td>10184_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15761</th>\n",
       "      <td>Imagine that you are asked by your date what m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1686_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>Moonwalker is absolutely incredible !!!!!!! Wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>5802_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19170</th>\n",
       "      <td>I loved the original. It was brilliant and alw...</td>\n",
       "      <td>0</td>\n",
       "      <td>4754_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>\"Tulip\" is on the \"Australian All Shorts\" vide...</td>\n",
       "      <td>1</td>\n",
       "      <td>1180_9.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file\n",
       "12704  For months I've been hearing about this little...      0  10184_1.txt\n",
       "15761  Imagine that you are asked by your date what m...      0   1686_1.txt\n",
       "7835   Moonwalker is absolutely incredible !!!!!!! Wh...      1  5802_10.txt\n",
       "19170  I loved the original. It was brilliant and alw...      0   4754_4.txt\n",
       "2010   \"Tulip\" is on the \"Australian All Shorts\" vide...      1   1180_9.txt"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11414</th>\n",
       "      <td>This was a very funny movie, not Oscar-worthy,...</td>\n",
       "      <td>1</td>\n",
       "      <td>9023_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18551</th>\n",
       "      <td>This is absolutely the most stupidest movie ev...</td>\n",
       "      <td>0</td>\n",
       "      <td>4197_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16536</th>\n",
       "      <td>Synopsis Correction: The ending does not show ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2383_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>Lovingly crafted and terribly interesting to w...</td>\n",
       "      <td>1</td>\n",
       "      <td>4904_7.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>This was a great movie. Something not only for...</td>\n",
       "      <td>1</td>\n",
       "      <td>54_10.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file\n",
       "11414  This was a very funny movie, not Oscar-worthy,...      1  9023_10.txt\n",
       "18551  This is absolutely the most stupidest movie ev...      0   4197_1.txt\n",
       "16536  Synopsis Correction: The ending does not show ...      0   2383_4.txt\n",
       "6837   Lovingly crafted and terribly interesting to w...      1   4904_7.txt\n",
       "7499   This was a great movie. Something not only for...      1    54_10.txt"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing\n",
    "Examining a sample review from the train and test data, we can clearly notice that the raw review data are uncleaned and messy. So before we can do some analysis we will need to clean that data. CLeaning the data will include removing unwanted text and symbols as well as converting the text data to lower cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine that you are asked by your date what movie you wanted to see, and you remember seeing a rather intriguing trailer about \"The Grudge.\" So, in good faith, you recommend seeing that movie. It is the Halloween season, after all. And it did boffo box office this past weekend, so it must be pretty good...so you go.<br /><br />And you\\'re actually in a state of shock when the movie ends the way it does, and you hear yourself audibly saying, \"that can\\'t be the end of the movie....\" But, alas, it is. <br /><br />And imagine coming out of the movie theater being embarrassed and ashamed for recommending such a dog of a movie. You think that your date thinks you\\'re a bonehead for suggesting such an atrocity, and your suggestion will certainly end a promising relationship. Actually, it was so bad that both of us cracked up laughing at how bad it was. I see no future for Miss Gellar in the movies, and suggest that she sticks to television in the future. Actually, it won\\'t be long before she is consigned to flea-market conventions selling Buffy memorabilia, and it can\\'t happen soon enough, if you ask me. Horrible, horrible, horrible. The plot didn\\'t make sense; continuity was terrible. It\\'s apparent that the whole ending was contrived to have a \"Grudge II--The Return of \\'Cat-Boy\\'.\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.iloc[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is absolutely the most stupidest movie ever produced in front of a camera. I cant believe I was gullable enough to rent this piece of junk. I have seen some bad movies in my time, But this takes the cake....Ice cream ,,,, and Chips Too. Omg, I still cant get over how bad this thing was. The acting was a Joke.... The Plot was Non Exsistant..and the camera work had to be done by a 3 year old child. I have never seen a movie take so long to go Nowhere. I mean the whole movie could have been shot is less than 30 minutes. I guess this guy had some extra time on his hands.... ( Like 3 Hours. ) And an extra 60 bucks in his wallet, and decided one night...( Hey ..Lets go make the stupidest movie ever made. ) And they did just that. Give me a break.I'm heading back to the video store right now to get Demand my money back.Anyone else who has watched this piece of trash, should do the same.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.iloc[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the messy data can easily be accomplished by using keyboard shortcuts like CTRL+F, CTRL+C, CTRL+V and DEL. But with this huge amount data, we needed a more efficient way of finding unwanted text and replacing it with the appropriate one. This is where **Regular Expression** or **regex** comes into picture. \n",
    "\n",
    "Regular expression is very essential in natural language processing. In this section we will use regular express to perform search and replace. To use regex we need import the python **re** library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one sample of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For months I\\'ve been hearing about this little movie and now I\\'ve seen it. I find it cute, cute how so many fledgling directors make movies where they combine other people\\'s creative ideas in order to make their own one-joke premise of a movie. Troops, Swingblade, any of the million Blair Witch parodies come to mind. If all that these directors want is a foot inside Hollywood\\'s door then they\\'re doing the right thing and they should keep it up because combining plot outlines is how Hollywood makes films. How many times have you heard the phrase, \"It\\'s Animal House meets Back to the Future\"; \"It\\'s Wall Street meets Dead Poet\\'s Society\"; or \"Shakespeare in Love meets Star Wars\"? I remember when independent films meant original and daring not safe and predictable.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, there are plenty of unwanted characters in the text data. To remove these characters we will create a function that  will search the unwanted characters and at the same time replace it with the appropriate characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = REPLACE_NO_SPACE.sub('', reviews.lower()) \n",
    "    reviews = REPLACE_WITH_SPACE.sub(' ', reviews)\n",
    "    \n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the train data\n",
    "train_reviews['tidy_review'] = np.vectorize(preprocess_reviews)(train_reviews['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the test data\n",
    "test_reviews['tidy_review'] = np.vectorize(preprocess_reviews)(test_reviews['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>tidy_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12704</th>\n",
       "      <td>For months I've been hearing about this little...</td>\n",
       "      <td>0</td>\n",
       "      <td>10184_1.txt</td>\n",
       "      <td>for months ive been hearing about this little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15761</th>\n",
       "      <td>Imagine that you are asked by your date what m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1686_1.txt</td>\n",
       "      <td>imagine that you are asked by your date what m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>Moonwalker is absolutely incredible !!!!!!! Wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>5802_10.txt</td>\n",
       "      <td>moonwalker is absolutely incredible  what else...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19170</th>\n",
       "      <td>I loved the original. It was brilliant and alw...</td>\n",
       "      <td>0</td>\n",
       "      <td>4754_4.txt</td>\n",
       "      <td>i loved the original it was brilliant and alwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>\"Tulip\" is on the \"Australian All Shorts\" vide...</td>\n",
       "      <td>1</td>\n",
       "      <td>1180_9.txt</td>\n",
       "      <td>tulip is on the australian all shorts video fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "12704  For months I've been hearing about this little...      0  10184_1.txt   \n",
       "15761  Imagine that you are asked by your date what m...      0   1686_1.txt   \n",
       "7835   Moonwalker is absolutely incredible !!!!!!! Wh...      1  5802_10.txt   \n",
       "19170  I loved the original. It was brilliant and alw...      0   4754_4.txt   \n",
       "2010   \"Tulip\" is on the \"Australian All Shorts\" vide...      1   1180_9.txt   \n",
       "\n",
       "                                             tidy_review  \n",
       "12704  for months ive been hearing about this little ...  \n",
       "15761  imagine that you are asked by your date what m...  \n",
       "7835   moonwalker is absolutely incredible  what else...  \n",
       "19170  i loved the original it was brilliant and alwa...  \n",
       "2010   tulip is on the australian all shorts video fr...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for months ive been hearing about this little movie and now ive seen it i find it cute cute how so many fledgling directors make movies where they combine other peoples creative ideas in order to make their own one joke premise of a movie troops swingblade any of the million blair witch parodies come to mind if all that these directors want is a foot inside hollywoods door then theyre doing the right thing and they should keep it up because combining plot outlines is how hollywood makes films how many times have you heard the phrase its animal house meets back to the future its wall street meets dead poets society or shakespeare in love meets star wars i remember when independent films meant original and daring not safe and predictable'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.iloc[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stop words\n",
    "Another preprocessing step that we can do to our data is removing stop words. Stop words are common word in a language that does not neccessarily help in identifying the context or the true meaning of a sentence. \n",
    "\n",
    "To remove the stop words from our data, we will tokenize each review data and compare each words or token to the list of stop words from the nltk stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "train_reviews['reviews_without_stopwords'] = train_reviews['tidy_review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "test_reviews['reviews_without_stopwords'] = test_reviews['tidy_review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>tidy_review</th>\n",
       "      <th>reviews_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12704</th>\n",
       "      <td>For months I've been hearing about this little...</td>\n",
       "      <td>0</td>\n",
       "      <td>10184_1.txt</td>\n",
       "      <td>for months ive been hearing about this little ...</td>\n",
       "      <td>months ive hearing little movie ive seen find ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15761</th>\n",
       "      <td>Imagine that you are asked by your date what m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1686_1.txt</td>\n",
       "      <td>imagine that you are asked by your date what m...</td>\n",
       "      <td>imagine asked date movie wanted see remember s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>Moonwalker is absolutely incredible !!!!!!! Wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>5802_10.txt</td>\n",
       "      <td>moonwalker is absolutely incredible  what else...</td>\n",
       "      <td>moonwalker absolutely incredible else say mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19170</th>\n",
       "      <td>I loved the original. It was brilliant and alw...</td>\n",
       "      <td>0</td>\n",
       "      <td>4754_4.txt</td>\n",
       "      <td>i loved the original it was brilliant and alwa...</td>\n",
       "      <td>loved original brilliant always strangely thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>\"Tulip\" is on the \"Australian All Shorts\" vide...</td>\n",
       "      <td>1</td>\n",
       "      <td>1180_9.txt</td>\n",
       "      <td>tulip is on the australian all shorts video fr...</td>\n",
       "      <td>tulip australian shorts video tribe first rite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "12704  For months I've been hearing about this little...      0  10184_1.txt   \n",
       "15761  Imagine that you are asked by your date what m...      0   1686_1.txt   \n",
       "7835   Moonwalker is absolutely incredible !!!!!!! Wh...      1  5802_10.txt   \n",
       "19170  I loved the original. It was brilliant and alw...      0   4754_4.txt   \n",
       "2010   \"Tulip\" is on the \"Australian All Shorts\" vide...      1   1180_9.txt   \n",
       "\n",
       "                                             tidy_review  \\\n",
       "12704  for months ive been hearing about this little ...   \n",
       "15761  imagine that you are asked by your date what m...   \n",
       "7835   moonwalker is absolutely incredible  what else...   \n",
       "19170  i loved the original it was brilliant and alwa...   \n",
       "2010   tulip is on the australian all shorts video fr...   \n",
       "\n",
       "                               reviews_without_stopwords  \n",
       "12704  months ive hearing little movie ive seen find ...  \n",
       "15761  imagine asked date movie wanted see remember s...  \n",
       "7835   moonwalker absolutely incredible else say mich...  \n",
       "19170  loved original brilliant always strangely thou...  \n",
       "2010   tulip australian shorts video tribe first rite...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample result after removing stop words:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'months ive hearing little movie ive seen find cute cute many fledgling directors make movies combine peoples creative ideas order make one joke premise movie troops swingblade million blair witch parodies come mind directors want foot inside hollywoods door theyre right thing keep combining plot outlines hollywood makes films many times heard phrase animal house meets back future wall street meets dead poets society shakespeare love meets star wars remember independent films meant original daring safe predictable'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.iloc[0,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "Stemming is a common step done in natural language processing. This is a process where in a word/s is reduced to its core root. \n",
    "One very popular algorithm that perform stemming is Porter Stemmer. This is already included in the NLTK library and we just need to import it and create and instance of the PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews['normalized'] = train_reviews['reviews_without_stopwords'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews['normalized'] = test_reviews['reviews_without_stopwords'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample result after stemming:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>tidy_review</th>\n",
       "      <th>reviews_without_stopwords</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12704</th>\n",
       "      <td>For months I've been hearing about this little...</td>\n",
       "      <td>0</td>\n",
       "      <td>10184_1.txt</td>\n",
       "      <td>for months ive been hearing about this little ...</td>\n",
       "      <td>months ive hearing little movie ive seen find ...</td>\n",
       "      <td>month ive hear littl movi ive seen find cute c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15761</th>\n",
       "      <td>Imagine that you are asked by your date what m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1686_1.txt</td>\n",
       "      <td>imagine that you are asked by your date what m...</td>\n",
       "      <td>imagine asked date movie wanted see remember s...</td>\n",
       "      <td>imagin ask date movi want see rememb see rathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>Moonwalker is absolutely incredible !!!!!!! Wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>5802_10.txt</td>\n",
       "      <td>moonwalker is absolutely incredible  what else...</td>\n",
       "      <td>moonwalker absolutely incredible else say mich...</td>\n",
       "      <td>moonwalk absolut incred els say michael jackso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19170</th>\n",
       "      <td>I loved the original. It was brilliant and alw...</td>\n",
       "      <td>0</td>\n",
       "      <td>4754_4.txt</td>\n",
       "      <td>i loved the original it was brilliant and alwa...</td>\n",
       "      <td>loved original brilliant always strangely thou...</td>\n",
       "      <td>love origin brilliant alway strang though actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>\"Tulip\" is on the \"Australian All Shorts\" vide...</td>\n",
       "      <td>1</td>\n",
       "      <td>1180_9.txt</td>\n",
       "      <td>tulip is on the australian all shorts video fr...</td>\n",
       "      <td>tulip australian shorts video tribe first rite...</td>\n",
       "      <td>tulip australian short video tribe first rite ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "12704  For months I've been hearing about this little...      0  10184_1.txt   \n",
       "15761  Imagine that you are asked by your date what m...      0   1686_1.txt   \n",
       "7835   Moonwalker is absolutely incredible !!!!!!! Wh...      1  5802_10.txt   \n",
       "19170  I loved the original. It was brilliant and alw...      0   4754_4.txt   \n",
       "2010   \"Tulip\" is on the \"Australian All Shorts\" vide...      1   1180_9.txt   \n",
       "\n",
       "                                             tidy_review  \\\n",
       "12704  for months ive been hearing about this little ...   \n",
       "15761  imagine that you are asked by your date what m...   \n",
       "7835   moonwalker is absolutely incredible  what else...   \n",
       "19170  i loved the original it was brilliant and alwa...   \n",
       "2010   tulip is on the australian all shorts video fr...   \n",
       "\n",
       "                               reviews_without_stopwords  \\\n",
       "12704  months ive hearing little movie ive seen find ...   \n",
       "15761  imagine asked date movie wanted see remember s...   \n",
       "7835   moonwalker absolutely incredible else say mich...   \n",
       "19170  loved original brilliant always strangely thou...   \n",
       "2010   tulip australian shorts video tribe first rite...   \n",
       "\n",
       "                                              normalized  \n",
       "12704  month ive hear littl movi ive seen find cute c...  \n",
       "15761  imagin ask date movi want see rememb see rathe...  \n",
       "7835   moonwalk absolut incred els say michael jackso...  \n",
       "19170  love origin brilliant alway strang though actu...  \n",
       "2010   tulip australian short video tribe first rite ...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
